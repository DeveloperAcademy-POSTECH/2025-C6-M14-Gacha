//
//  CameraManager.swift
//  gacha
//
//  Created by Oh Seojin on 10/20/25.
//

import AVFoundation
import Combine
import SwiftUI
import UIKit
import Vision

let FLEXION_BASIC_ANGLE: Double = 90.0
let EXTENSION_BASIC_ANGLE: Double = 0.0


// MARK: - ì¹´ë©”ë¼ ë§¤ë‹ˆì €
/// ì¹´ë©”ë¼ ì„¸ì…˜ì„ ê´€ë¦¬í•˜ê³  Visionì„ ì´ìš©í•´ ì‹ ì²´ë¥¼ ê°ì§€í•˜ëŠ” í´ë˜ìŠ¤
class CameraManager: NSObject, ObservableObject {

    // ì¹´ë©”ë¼ ê´€ë ¨
    private let captureSession = AVCaptureSession()
    private let videoOutput = AVCaptureVideoDataOutput()
    private let sessionQueue = DispatchQueue(label: "camera.session.queue")

    // Vision ê´€ë ¨
    private var bodyPoseRequest = VNDetectHumanBodyPoseRequest()

    // ê°ì§€ëœ ë°ì´í„° - Viewì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ Publish
    @Published var detectedBody: DetectedBody?
    @Published var currentAngles: BodyAngles?

    @Published var isRecording: Bool = false
    @Published var flexionAngle: Double?
    @Published var extensionAngle: Double?

    private var currentPixelBuffer: CVPixelBuffer?  // â­ í˜„ì¬ í”„ë ˆì„ì˜ pixelBuffer ì €ì¥ìš©
    private var flexionAngleImage: UIImage?  // êµ´ê³¡ ì‹œ ì´ë¯¸ì§€
    private var extensionAngleImage: UIImage?  // ì‹ ì „ ì‹œ ì´ë¯¸ì§€

    var previewLayer: AVCaptureVideoPreviewLayer?

    override init() {
        super.init()
        setupCamera()
    }

    /// ì¹´ë©”ë¼ ì´ˆê¸° ì„¤ì •
    private func setupCamera() {
        // (1) ì¹´ë©”ë¼ ë””ë°”ì´ìŠ¤ ì„¤ì •: ì „ë©´
        guard
            let camera = AVCaptureDevice.default(
                .builtInWideAngleCamera,
                for: .video,
                position: .back
            )
        else {
            print("âŒ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        }

        do {
            let input = try AVCaptureDeviceInput(device: camera)

            // (2) ì„¸ì…˜ ì„¤ì • ì‹œì‘
            captureSession.beginConfiguration()

            // (3) ì…ë ¥ì„ ì„¸ì…˜ì— ì¶”ê°€
            if captureSession.canAddInput(input) {
                captureSession.addInput(input)
            }

            // (4) ì„¸ì…˜ í’ˆì§ˆ ì„¤ì •
            if captureSession.canSetSessionPreset(.hd1280x720) {
                captureSession.sessionPreset = .hd1280x720
            }

            // (5) ë¹„ë””ì˜¤ ì¶œë ¥ ì„¤ì •
            videoOutput.setSampleBufferDelegate(self, queue: sessionQueue)

            // (6) ì¶œë ¥ì„ ì„¸ì…˜ì— ì¶”ê°€
            if captureSession.canAddOutput(videoOutput) {
                captureSession.addOutput(videoOutput)
            }

            // (7) ë ˆì´ì–´ ì„¤ì • ì™„ë£Œ
            captureSession.commitConfiguration()

            // (8) í”„ë¦¬ë·° ë ˆì´ì–´ ìƒì„±
            let previewLayer = AVCaptureVideoPreviewLayer(
                session: captureSession
            )
            previewLayer.videoGravity = .resizeAspectFill

            // (9) í”„ë¦¬ë·°ì˜ ë ˆì´ì–´ ì—°ê²°ì—ì„œ ë°©í–¥ì„ ê°€ë¡œ ë°©í–¥ìœ¼ë¡œ ì„¤ì • (Landscape Right)
            if let connection = previewLayer.connection {
                connection.videoRotationAngle = 0
                print("âœ… í”„ë¦¬ë·° ë ˆì´ì–´ íšŒì „ ì„¤ì •: 180ë„")
            } else {
                print("âš ï¸ í”„ë¦¬ë·° ë ˆì´ì–´ ì—°ê²°ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            }

            // (10) í”„ë¦¬ë·° ì„¤ì • ì™„ë£Œ
            self.previewLayer = previewLayer
            print("âœ… ì¹´ë©”ë¼ ì„¤ì • ì™„ë£Œ")

        } catch {
            print("âŒ ì¹´ë©”ë¼ ì„¤ì • ì—ëŸ¬: \(error.localizedDescription)")
        }
    }

    /// ì¹´ë©”ë¼ ì„¸ì…˜ ì‹œì‘
    func startSession() {
        print("â–¶ï¸ ì¹´ë©”ë¼ ì„¸ì…˜ ì‹œì‘ ìš”ì²­")
        sessionQueue.async { [weak self] in
            self?.captureSession.startRunning()
            print("â–¶ï¸ ì¹´ë©”ë¼ ì„¸ì…˜ ì‹¤í–‰ ì¤‘")
        }
    }

    /// ì¹´ë©”ë¼ ì„¸ì…˜ ì¢…ë£Œ
    func stopSession() {
        print("â¹ï¸ ì¹´ë©”ë¼ ì„¸ì…˜ ì¢…ë£Œ ìš”ì²­")
        sessionQueue.async { [weak self] in
            self?.captureSession.stopRunning()
            print("â¹ï¸ ì¹´ë©”ë¼ ì„¸ì…˜ ì¢…ë£Œë¨")
        }
    }

    func startRecording() {
        isRecording = true
        flexionAngle = nil
        extensionAngle = nil

        print("ğŸ“¸ ì¸¡ì • ì‹œì‘")
    }

    func stopRecording() -> MeasuredRecord? {
        isRecording = false

        // image ì¸ì•±ì— ì €ì¥
        if let flexionImage = flexionAngleImage,
            let extensionImage = extensionAngleImage
        {
            let result = saveImage(flexionImage, extensionImage)
            
            if let result = result {
                return MeasuredRecord(
                    flexionAngle: Int(flexionAngle ?? FLEXION_BASIC_ANGLE),
                    extensionAngle: Int(extensionAngle ?? EXTENSION_BASIC_ANGLE),
                    isDeleted: false,
                    flexionImage_id: "\(result.0)",
                    extensionImage_id: "\(result.1)"
                )
            } else {
                print("ğŸš¨ ì´ë¯¸ì§€ ì €ì¥ ì˜¤ë¥˜")
                return nil
            }
        } else {
            print("ğŸš¨ ì´ë¯¸ì§€ ì €ì¥ ì˜¤ë¥˜")
            return nil
        }
    }
}

// MARK: - ë¹„ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬
extension CameraManager: AVCaptureVideoDataOutputSampleBufferDelegate {
    /// ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì´ ìº¡ì²˜ë  ë•Œë§ˆë‹¤ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜
    func captureOutput(
        _ output: AVCaptureOutput,
        didOutput sampleBuffer: CMSampleBuffer,
        from connection: AVCaptureConnection
    ) {

        if !isRecording { return }

        // 1. í”„ë ˆì„ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer)
        else { return }

        // â­ 2. í˜„ì¬ pixelBufferë¥¼ ì €ì¥ (ì´ë¯¸ì§€ ìº¡ì²˜ìš©)
        if isRecording {
            self.currentPixelBuffer = pixelBuffer
        }

        // 3. Vision ìš”ì²­ í•¸ë“¤ëŸ¬ ìƒì„±
        let handler = VNImageRequestHandler(
            cvPixelBuffer: pixelBuffer,
            options: [:]
        )

        // 4. ì‹ ì²´ ê°ì§€ ìš”ì²­ ì‹¤í–‰
        do {
            try handler.perform([bodyPoseRequest])

            guard let observation = bodyPoseRequest.results?.first else {
                return
            }

            // 5. ì‹ ì²´ í¬ì¦ˆ ì²˜ë¦¬ (ê°ë„ ê³„ì‚° ë° ì´ë¯¸ì§€ ì €ì¥)
            processBodyPose(observation: observation)

        } catch {
            print("âŒ Vision ìš”ì²­ ì‹¤íŒ¨: \(error.localizedDescription)")
        }
    }

    /// ê°ì§€ëœ ì‹ ì²´ í¬ì¦ˆë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    private func processBodyPose(observation: VNHumanBodyPoseObservation) {
        // ì£¼ìš” ê´€ì ˆ í¬ì¸íŠ¸ ì¶”ì¶œ
        guard
            let recognizedPoints = try? observation.recognizedPoints(.rightLeg)
        else { return }

        // ì‹ ë¢°ë„ê°€ ë†’ì€ í¬ì¸íŠ¸ë§Œ í•„í„°ë§ (0.3 ì´ìƒìœ¼ë¡œ ë‚®ì¶¤ - ë” ë§ì€ í¬ì¸íŠ¸ ê°ì§€)
        let validPoints = recognizedPoints.filter { $0.value.confidence > 0.3 }

        // ë””ë²„ê·¸: ê°ì§€ëœ ê´€ì ˆ ì •ë³´ ì¶œë ¥
//        #if DEBUG
//            let kneePoints = validPoints.filter {
//                $0.key == .leftKnee || $0.key == .rightKnee
//                    || $0.key == .leftHip || $0.key == .rightHip
//                    || $0.key == .leftAnkle || $0.key == .rightAnkle
//            }
//            if !kneePoints.isEmpty {
//                print("ğŸ“ ê°ì§€ëœ í•˜ì²´ ê´€ì ˆ:")
//                for (joint, point) in kneePoints {
//                    print(
//                        "  \(joint.rawValue): ì‹ ë¢°ë„ \(String(format: "%.2f", point.confidence))"
//                    )
//                }
//            }
//        #endif

        // DetectedBody ê°ì²´ ìƒì„±
        let body = DetectedBody(points: validPoints)

        guard let angles = calculateAngles(from: validPoints) else {
            print("âš ï¸ ê°ë„ ê³„ì‚° ì‹¤íŒ¨")
            return
        }

        // UI ì—…ë°ì´íŠ¸ (ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ)
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }

            self.detectedBody = body
            self.currentAngles = angles

            guard let angle = angles.rightKnee ?? angles.leftKnee else {
                print("âš ï¸ ë¬´ë¦ ê°ë„ ê°ì§€ ì‹¤íŒ¨")
                return
            }

            let angleDifferenceThreshold = 30.0

            // êµ´ê³¡ ê°ë„(ìµœì†Œ) ì—…ë°ì´íŠ¸
            if self.flexionAngle == nil {
                self.flexionAngle = angle
                self.flexionAngleImage = self.captureCurrentFrame()  // â­ ì´ë¯¸ì§€ ìº¡ì²˜
                print("ğŸ”½ ì´ˆê¸° êµ´ê³¡ ê°ë„: \(String(format: "%.1f", angle))Â°")
            } else if angle < self.flexionAngle! {
                let difference = abs(angle - self.flexionAngle!)
                if difference < angleDifferenceThreshold {
                    self.flexionAngle = angle
                    self.flexionAngleImage = self.captureCurrentFrame()  // â­ ì´ë¯¸ì§€ ìº¡ì²˜
                    print(
                        "ğŸ”½ êµ´ê³¡ ê°ë„ ì—…ë°ì´íŠ¸: \(String(format: "%.1f", angle))Â° (ì´ë¯¸ì§€ ì €ì¥)"
                    )
                }
            }

            // ì‹ ì „ ê°ë„(ìµœëŒ€) ì—…ë°ì´íŠ¸
            if self.extensionAngle == nil {
                self.extensionAngle = angle
                self.extensionAngleImage = self.captureCurrentFrame()  // â­ ì´ë¯¸ì§€ ìº¡ì²˜
                print("ğŸ”¼ ì´ˆê¸° ì‹ ì „ ê°ë„: \(String(format: "%.1f", angle))Â°")
            } else if angle > self.extensionAngle! {
                let difference = abs(angle - self.extensionAngle!)
                if difference < angleDifferenceThreshold {
                    self.extensionAngle = angle
                    self.extensionAngleImage = self.captureCurrentFrame()  // â­ ì´ë¯¸ì§€ ìº¡ì²˜
                    print(
                        "ğŸ”¼ ì‹ ì „ ê°ë„ ì—…ë°ì´íŠ¸: \(String(format: "%.1f", angle))Â° (ì´ë¯¸ì§€ ì €ì¥)"
                    )
                }
            }
        }
    }

    /// ê´€ì ˆ í¬ì¸íŠ¸ë“¤ë¡œë¶€í„° ê°ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    private func calculateAngles(
        from points: [VNHumanBodyPoseObservation.JointName: VNRecognizedPoint]
    ) -> BodyAngles? {

        // ë¬´ë¦ ê°ë„ë§Œ ê³„ì‚° (íŒ” ê°ë„ëŠ” nilë¡œ ì„¤ì •)

        // ì˜¤ë¥¸ìª½ ë¬´ë¦ ê°ë„ ê³„ì‚° (ì—‰ë©ì´-ë¬´ë¦-ë°œëª©)
        let rightKneeAngle = calculateAngle(
            point1: points[.rightHip],
            point2: points[.rightKnee],
            point3: points[.rightAnkle]
        )

        // ì™¼ìª½ ë¬´ë¦ ê°ë„ ê³„ì‚°
        let leftKneeAngle = calculateAngle(
            point1: points[.leftHip],
            point2: points[.leftKnee],
            point3: points[.leftAnkle]
        )

        // ë””ë²„ê·¸: ê°ë„ ê³„ì‚° ê²°ê³¼ ì¶œë ¥
        #if DEBUG
            if let rightAngle = rightKneeAngle {
                print("  âœ… ì˜¤ë¥¸ìª½ ë¬´ë¦ ê°ë„: \(String(format: "%.1f", rightAngle))Â°")
            } else {
                print("  âŒ ì˜¤ë¥¸ìª½ ë¬´ë¦ ê°ë„ ê³„ì‚° ì‹¤íŒ¨")
            }

            if let leftAngle = leftKneeAngle {
                print("  âœ… ì™¼ìª½ ë¬´ë¦ ê°ë„: \(String(format: "%.1f", leftAngle))Â°")
            } else {
                print("  âŒ ì™¼ìª½ ë¬´ë¦ ê°ë„ ê³„ì‚° ì‹¤íŒ¨")
            }
        #endif

        return BodyAngles(
            rightKnee: rightKneeAngle,
            leftKnee: leftKneeAngle
        )
    }

    /// ì„¸ ì ìœ¼ë¡œ ê°ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    /// - Parameters:
    ///   - point1: ì²« ë²ˆì§¸ ì  (ì˜ˆ: ì–´ê¹¨)
    ///   - point2: ì¤‘ê°„ ì  (ì˜ˆ: íŒ”ê¿ˆì¹˜) - ê°ë„ì˜ ê¼­ì§“ì 
    ///   - point3: ì„¸ ë²ˆì§¸ ì  (ì˜ˆ: ì†ëª©)
    /// - Returns: ê°ë„ (degree)
    private func calculateAngle(
        point1: VNRecognizedPoint?,
        point2: VNRecognizedPoint?,
        point3: VNRecognizedPoint?
    ) -> Double? {
        guard let p1 = point1, let p2 = point2, let p3 = point3 else {
            return nil
        }

        // 1. ë²¡í„° ìƒì„±
        let vector1 = CGPoint(
            x: p1.location.x - p2.location.x,
            y: p1.location.y - p2.location.y
        )
        let vector2 = CGPoint(
            x: p3.location.x - p2.location.x,
            y: p3.location.y - p2.location.y
        )

        // 2. ë‚´ì  ê³„ì‚°
        let dotProduct = vector1.x * vector2.x + vector1.y * vector2.y

        // 3. ë²¡í„° í¬ê¸° ê³„ì‚°
        let magnitude1 = sqrt(vector1.x * vector1.x + vector1.y * vector1.y)
        let magnitude2 = sqrt(vector2.x * vector2.x + vector2.y * vector2.y)

        // 4. ì½”ì‚¬ì¸ ê°’ ê³„ì‚°
        let cosine = dotProduct / (magnitude1 * magnitude2)

        // 5. ë¼ë””ì•ˆì„ ê°ë„ë¡œ ë³€í™˜
        let angleInRadians = acos(min(max(cosine, -1), 1))  // -1 ~ 1 ì‚¬ì´ë¡œ ì œí•œ
        let angleInDegrees = angleInRadians * 180 / .pi

        return angleInDegrees
    }

    /// í˜„ì¬ ì €ì¥ëœ pixelBufferë¥¼ UIImageë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
    private func captureCurrentFrame() -> UIImage? {
        guard let pixelBuffer = currentPixelBuffer else {
            print("âš ï¸ ì €ì¥ëœ pixelBufferê°€ ì—†ìŒ")
            return nil
        }

        guard var image = pixelBufferToUIImage(pixelBuffer) else { return nil }

        if let compressedData = image.jpegData(compressionQuality: 0.8) {
            image = UIImage(data: compressedData) ?? image
            print("ğŸ“¸ ì´ë¯¸ì§€ ìº¡ì²˜ ë° ì••ì¶• ì™„ë£Œ")
        }

        return image
    }

    /// CVPixelBufferë¥¼ UIImageë¡œ ë³€í™˜
    private func pixelBufferToUIImage(_ pixelBuffer: CVPixelBuffer) -> UIImage?
    {
        // 1. CVPixelBufferë¥¼ CIImageë¡œ ë³€í™˜
        let ciImage = CIImage(cvPixelBuffer: pixelBuffer)

        // 2. CIContext ìƒì„± (í•œ ë²ˆë§Œ ìƒì„±í•´ì„œ ì¬ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ)
        let context = CIContext()

        // 3. CIImageë¥¼ CGImageë¡œ ë³€í™˜
        guard let cgImage = context.createCGImage(ciImage, from: ciImage.extent)
        else {
            print("âŒ CGImage ë³€í™˜ ì‹¤íŒ¨")
            return nil
        }

        // 4. CGImageë¥¼ UIImageë¡œ ë³€í™˜
        // íšŒì „ ê°ë„ ê³ ë ¤ (ì¹´ë©”ë¼ ë°©í–¥ì— ë§ì¶° ì¡°ì •)
        let image = UIImage(cgImage: cgImage, scale: 1.0, orientation: .right)

        return image
    }
}
