//
//  CameraManager.swift
//  gacha
//
//  Created by Oh Seojin on 10/20/25.
//

import AVFoundation
import Combine
import SwiftUI
import UIKit
import Vision

let FLEXION_BASIC_ANGLE: Double = 90.0
let EXTENSION_BASIC_ANGLE: Double = 0.0

// MARK: - ì¹´ë©”ë¼ ë§¤ë‹ˆì €
/// ì¹´ë©”ë¼ ì„¸ì…˜ì„ ê´€ë¦¬í•˜ê³  Visionì„ ì´ìš©í•´ ì‹ ì²´ë¥¼ ê°ì§€í•˜ëŠ” í´ë˜ìŠ¤
class CameraManager: NSObject, ObservableObject {
    // ì¹´ë©”ë¼ ê´€ë ¨
    private let captureSession = AVCaptureSession()
    private let videoOutput = AVCaptureVideoDataOutput()
    private let sessionQueue = DispatchQueue(label: "camera.session.queue")

    // Vision ê´€ë ¨
    private var bodyPoseRequest = VNDetectHumanBodyPoseRequest()

    // ì‹ ë¢°ë„ ì„ê³„ê°’
    private let minJointConfidence: Float = 0.5

    // ì¤€ë¹„ ìì„¸ ê°ì§€ ê´€ë ¨ ì¶”ê°€
    @Published var isInReadyPosition: Bool = false  // ì¤€ë¹„ ìì„¸ì¸ì§€ ì—¬ë¶€
    @Published var readyPositionProgress: Double = 0.0  // ì§„í–‰ë¥  (0.0 ~ 1.0)

    private var readyPositionStartTime: Date?  // ì¤€ë¹„ ìì„¸ ì‹œì‘ ì‹œê°„
    private let readyAngleMin: Double = 150.0  // ì¤€ë¹„ ìì„¸ ìµœì†Œ ê°ë„
    private let readyAngleMax: Double = 180.0  // ì¤€ë¹„ ìì„¸ ìµœëŒ€ ê°ë„
    private let readyPositionDuration: TimeInterval = 2.0

    private var readyCheckTimer: Timer?  // íƒ€ì´ë¨¸

    // ê°ì§€ëœ ë°ì´í„° - Viewì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ Publish
    @Published var detectedBody: DetectedBody?
    @Published var currentAngles: BodyAngles?

    @Published var isMeasuring: Bool = false
    @Published var selectedKnee: KneeSelection = .right
    @Published var flexionAngle: Double?
    @Published var extensionAngle: Double?

    private var currentPixelBuffer: CVPixelBuffer?  // í˜„ì¬ í”„ë ˆì„ì˜ pixelBuffer ì €ì¥ìš©
    private var flexionAngleImage: UIImage?  // êµ´ê³¡ ì‹œ ì´ë¯¸ì§€
    private var extensionAngleImage: UIImage?  // ì‹ ì „ ì‹œ ì´ë¯¸ì§€

    var previewLayer: AVCaptureVideoPreviewLayer?

    override init() {
        super.init()
        setupCamera()
    }

    /// ì¹´ë©”ë¼ ì´ˆê¸° ì„¤ì •
    private func setupCamera() {
        // (1) ì¹´ë©”ë¼ ë””ë°”ì´ìŠ¤ ì„¤ì •: ì „ë©´
        guard
            let camera = AVCaptureDevice.default(
                .builtInWideAngleCamera,
                for: .video,
                position: .back
            )
        else {
            print("âŒ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        }

        do {
            let input = try AVCaptureDeviceInput(device: camera)

            // (2) ì„¸ì…˜ ì„¤ì • ì‹œì‘
            captureSession.beginConfiguration()

            // (3) ì…ë ¥ì„ ì„¸ì…˜ì— ì¶”ê°€
            if captureSession.canAddInput(input) {
                captureSession.addInput(input)
            }

            // (4) ì„¸ì…˜ í’ˆì§ˆ ì„¤ì •
            if captureSession.canSetSessionPreset(.hd1280x720) {
                captureSession.sessionPreset = .hd1280x720
            }

            // (5) ë¹„ë””ì˜¤ ì¶œë ¥ ì„¤ì •
            videoOutput.setSampleBufferDelegate(self, queue: sessionQueue)

            // (6) ì¶œë ¥ì„ ì„¸ì…˜ì— ì¶”ê°€
            if captureSession.canAddOutput(videoOutput) {
                captureSession.addOutput(videoOutput)
            }

            // (7) ë ˆì´ì–´ ì„¤ì • ì™„ë£Œ
            captureSession.commitConfiguration()

            // (8) í”„ë¦¬ë·° ë ˆì´ì–´ ìƒì„±
            let previewLayer = AVCaptureVideoPreviewLayer(
                session: captureSession
            )
            previewLayer.videoGravity = .resizeAspectFill

            // (9) í”„ë¦¬ë·°ì˜ ë ˆì´ì–´ ì—°ê²°ì—ì„œ ë°©í–¥ì„ ê°€ë¡œ ë°©í–¥ìœ¼ë¡œ ì„¤ì • (Landscape Right)
            if let connection = previewLayer.connection {
                connection.videoRotationAngle = 90
                print("âœ… í”„ë¦¬ë·° ë ˆì´ì–´ íšŒì „ ì„¤ì •: 90ë„")
            } else {
                print("âš ï¸ í”„ë¦¬ë·° ë ˆì´ì–´ ì—°ê²°ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            }

            // (10) í”„ë¦¬ë·° ì„¤ì • ì™„ë£Œ
            self.previewLayer = previewLayer
            print("âœ… ì¹´ë©”ë¼ ì„¤ì • ì™„ë£Œ")

        } catch {
            print("âŒ ì¹´ë©”ë¼ ì„¤ì • ì—ëŸ¬: \(error.localizedDescription)")
        }
    }

    /// ì¹´ë©”ë¼ ì„¸ì…˜ ì‹œì‘
    func startSession() {
        print("â–¶ï¸ ì¹´ë©”ë¼ ì„¸ì…˜ ì‹œì‘ ìš”ì²­")
        sessionQueue.async { [weak self] in
            self?.captureSession.startRunning()
            print("â–¶ï¸ ì¹´ë©”ë¼ ì„¸ì…˜ ì‹¤í–‰ ì¤‘")

            // ì¹´ë©”ë¼ ì¤€ë¹„ ì™„ë£Œ - WatchLink ìƒíƒœ ì—…ë°ì´íŠ¸ (ì €ì¥ + ë¸Œë¡œë“œìºìŠ¤íŠ¸)
            #if os(iOS)
                WatchLink.shared.setCameraReady(true)
            #endif
        }
    }

    /// ì¹´ë©”ë¼ ì„¸ì…˜ ì¢…ë£Œ
    func stopSession() {
        print("â¹ï¸ ì¹´ë©”ë¼ ì„¸ì…˜ ì¢…ë£Œ ìš”ì²­")

        // â­ ì¤€ë¹„ ìì„¸ íƒ€ì´ë¨¸ ì •ë¦¬
        readyCheckTimer?.invalidate()
        readyCheckTimer = nil

        sessionQueue.async { [weak self] in
            self?.captureSession.stopRunning()
            print("â¹ï¸ ì¹´ë©”ë¼ ì„¸ì…˜ ì¢…ë£Œë¨")

            // ì¹´ë©”ë¼ ì¤€ë¹„ í•´ì œ - WatchLink ìƒíƒœ ì—…ë°ì´íŠ¸ (ì €ì¥ + ë¸Œë¡œë“œìºìŠ¤íŠ¸)
            #if os(iOS)
                WatchLink.shared.setCameraReady(false)
            #endif
        }
    }

    func startMeasuring() {
        // ì´ë¯¸ ì¸¡ì • ì¤‘ì´ë©´ ë¬´ì‹œ
        guard !isMeasuring else {
            print("âš ï¸ ì´ë¯¸ ì¸¡ì • ì¤‘ì…ë‹ˆë‹¤")
            return
        }

        isMeasuring = true
        flexionAngle = nil
        extensionAngle = nil

        print("ğŸ“¸ ì¸¡ì • ì‹œì‘")

        // WatchLink ìƒíƒœ ì—…ë°ì´íŠ¸ (ì €ì¥ + ë¸Œë¡œë“œìºìŠ¤íŠ¸)
        #if os(iOS)
            WatchLink.shared.setMeasuring(true)
        #endif
    }

    func stopMeasuring() -> MeasuredRecord? {
        // ì¸¡ì • ì¤‘ì´ ì•„ë‹ˆë©´ ë¬´ì‹œ
        guard isMeasuring else {
            print("âš ï¸ ì¸¡ì • ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤")
            return nil
        }

        isMeasuring = false

        print("â¹ï¸ ì¸¡ì • ì¢…ë£Œ")

        // WatchLink ìƒíƒœ ì—…ë°ì´íŠ¸ (ì €ì¥ + ë¸Œë¡œë“œìºìŠ¤íŠ¸)
        #if os(iOS)
            WatchLink.shared.setMeasuring(false)
        #endif

        // image ì¸ì•±ì— ì €ì¥
        if let flexionImage = flexionAngleImage,
            let extensionImage = extensionAngleImage
        {
            let result = saveImage(flexionImage, extensionImage)

            if let result = result {
                return MeasuredRecord(
                    flexionAngle: Int(flexionAngle ?? FLEXION_BASIC_ANGLE),
                    extensionAngle: Int(
                        extensionAngle ?? EXTENSION_BASIC_ANGLE
                    ),
                    isDeleted: false,
                    flexionImage_id: "\(result.0)",
                    extensionImage_id: "\(result.1)"
                )
            } else {
                print("ğŸš¨ ì´ë¯¸ì§€ ì €ì¥ ì˜¤ë¥˜")
                return nil
            }
        } else {
            print("ğŸš¨ ì´ë¯¸ì§€ ì €ì¥ ì˜¤ë¥˜")
            return nil
        }
    }
}

// MARK: - ë¹„ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬
extension CameraManager: AVCaptureVideoDataOutputSampleBufferDelegate {
    /// ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì´ ìº¡ì²˜ë  ë•Œë§ˆë‹¤ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜
    func captureOutput(
        _ output: AVCaptureOutput,
        didOutput sampleBuffer: CMSampleBuffer,
        from connection: AVCaptureConnection
    ) {
        // 1. í”„ë ˆì„ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer)
        else { return }

        // 2. í˜„ì¬ pixelBufferë¥¼ ì €ì¥ (ì´ë¯¸ì§€ ìº¡ì²˜ìš©)
        self.currentPixelBuffer = pixelBuffer

        // 3. Vision ìš”ì²­ í•¸ë“¤ëŸ¬ ìƒì„±
        let handler = VNImageRequestHandler(
            cvPixelBuffer: pixelBuffer,
            orientation: .right,
            options: [:]
        )

        // 4. ì‹ ì²´ ê°ì§€ ìš”ì²­ ì‹¤í–‰
        do {
            try handler.perform([bodyPoseRequest])

            guard let observation = bodyPoseRequest.results?.first else {
                return
            }

            // 5. ì‹ ì²´ í¬ì¦ˆ ì²˜ë¦¬ (ê°ë„ ê³„ì‚° ë° ì´ë¯¸ì§€ ì €ì¥)
            processBodyPose(observation: observation, pixelBuffer: pixelBuffer)

        } catch {
            print("âŒ Vision ìš”ì²­ ì‹¤íŒ¨: \(error.localizedDescription)")
        }
    }

    /// ê°ì§€ëœ ì‹ ì²´ í¬ì¦ˆë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    private func processBodyPose(
        observation: VNHumanBodyPoseObservation,
        pixelBuffer: CVPixelBuffer
    ) {
        // ì£¼ìš” ê´€ì ˆ í¬ì¸íŠ¸ ì¶”ì¶œ
        guard
            let recognizedPoints = try? observation.recognizedPoints(
                selectedKnee.jointGroupForSelectedKnee()
            )
        else { return }

        // ì‹ ë¢°ë„ê°€ ë†’ì€ í¬ì¸íŠ¸ë§Œ í•„í„°ë§
        let validPoints = recognizedPoints.filter {
            $0.value.confidence > minJointConfidence
        }

        // DetectedBody ê°ì²´ ìƒì„±
        let body = DetectedBody(points: validPoints)

        guard let angles = calculateAngles(from: validPoints) else {
            print("âš ï¸ ê°ë„ ê³„ì‚° ì‹¤íŒ¨")
            return
        }

        // UI ì—…ë°ì´íŠ¸ (ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ)
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }

            self.detectedBody = body
            self.currentAngles = angles

            guard let angle = angles.rightKnee ?? angles.leftKnee else {
                print("âš ï¸ ë¬´ë¦ ê°ë„ ê°ì§€ ì‹¤íŒ¨")
                return
            }

            // ì¸¡ì • ì¤‘ì´ ì•„ë‹ ë•Œë§Œ ì¤€ë¹„ ìì„¸ ì²´í¬
            if !self.isMeasuring {
                self.checkReadyPosition(angle)
            }

            // ì¸¡ì • ì¤‘ì¼ ë•Œ ê°ë„ ì—…ë°ì´íŠ¸
            if self.isMeasuring {
                // ê°ë„ ì—…ë°ì´íŠ¸
                self.updateAngleInfo(angle, pixelBuffer: pixelBuffer)
            }
        }
    }

    /// ì¤€ë¹„ ìì„¸ ì²´í¬
    private func checkReadyPosition(_ angle: Double) {
        if isAngleInReadyRange(angle) {
            // ì¤€ë¹„ ìì„¸ ë²”ìœ„ ë‚´
            if readyPositionStartTime == nil {
                startReadyPositionTracking()
            }
        } else {
            // ì¤€ë¹„ ìì„¸ ë²”ìœ„ ë²—ì–´ë‚¨
            if readyPositionStartTime != nil {
                stopReadyPositionTracking()
            }
        }
    }

    ///
    private func updateAngleInfo(_ angle: Double, pixelBuffer: CVPixelBuffer) {
        let angleDifferenceThreshold = 30.0

        // êµ´ê³¡ ê°ë„(ìµœì†Œ) ì—…ë°ì´íŠ¸
        if self.flexionAngle == nil {
            self.flexionAngle = angle
            self.flexionAngleImage = self.captureCurrentFrame()  // â­ ì´ë¯¸ì§€ ìº¡ì²˜
            print("ğŸ”½ ì´ˆê¸° êµ´ê³¡ ê°ë„: \(String(format: "%.1f", angle))Â°")
        } else if angle < self.flexionAngle! {
            let difference = abs(angle - self.flexionAngle!)
            if difference < angleDifferenceThreshold {
                self.flexionAngle = angle
                self.flexionAngleImage = self.captureCurrentFrame()  // â­ ì´ë¯¸ì§€ ìº¡ì²˜
                print(
                    "ğŸ”½ êµ´ê³¡ ê°ë„ ì—…ë°ì´íŠ¸: \(String(format: "%.1f", angle))Â° (ì´ë¯¸ì§€ ì €ì¥)"
                )
            }
        }

        // ì‹ ì „ ê°ë„(ìµœëŒ€) ì—…ë°ì´íŠ¸
        if self.extensionAngle == nil {
            self.extensionAngle = angle
            self.extensionAngleImage = self.captureCurrentFrame()  // â­ ì´ë¯¸ì§€ ìº¡ì²˜
            print("ğŸ”¼ ì´ˆê¸° ì‹ ì „ ê°ë„: \(String(format: "%.1f", angle))Â°")
        } else if angle > self.extensionAngle! {
            let difference = abs(angle - self.extensionAngle!)
            if difference < angleDifferenceThreshold {
                self.extensionAngle = angle
                self.extensionAngleImage = self.captureCurrentFrame()  // â­ ì´ë¯¸ì§€ ìº¡ì²˜
                print(
                    "ğŸ”¼ ì‹ ì „ ê°ë„ ì—…ë°ì´íŠ¸: \(String(format: "%.1f", angle))Â° (ì´ë¯¸ì§€ ì €ì¥)"
                )
            }
        }
    }

    /// ê´€ì ˆ í¬ì¸íŠ¸ë“¤ë¡œë¶€í„° ê°ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    private func calculateAngles(
        from points: [VNHumanBodyPoseObservation.JointName: VNRecognizedPoint]
    ) -> BodyAngles? {

        var rightKneeAngle: Double? = nil
        var leftKneeAngle: Double? = nil

        // â­ ì„ íƒëœ ë¬´ë¦ì— ë”°ë¼ ê³„ì‚°
        switch selectedKnee {
        case .right:
            // ì˜¤ë¥¸ìª½ ë¬´ë¦ë§Œ ê³„ì‚°
            rightKneeAngle = calculateAngle(
                point1: points[.rightHip],
                point2: points[.rightKnee],
                point3: points[.rightAnkle]
            )
            if let angle = rightKneeAngle {
                print("ğŸ“ ì˜¤ë¥¸ìª½ ë¬´ë¦ ê°ë„: \(String(format: "%.1f", angle))Â°")
            }

        case .left:
            // ì™¼ìª½ ë¬´ë¦ë§Œ ê³„ì‚°
            leftKneeAngle = calculateAngle(
                point1: points[.leftHip],
                point2: points[.leftKnee],
                point3: points[.leftAnkle]
            )
            if let angle = leftKneeAngle {
                print("ğŸ“ ì™¼ìª½ ë¬´ë¦ ê°ë„: \(String(format: "%.1f", angle))Â°")
            }

        case .both:
            // ì–‘ìª½ ëª¨ë‘ ê³„ì‚°
            rightKneeAngle = calculateAngle(
                point1: points[.rightHip],
                point2: points[.rightKnee],
                point3: points[.rightAnkle]
            )
            leftKneeAngle = calculateAngle(
                point1: points[.leftHip],
                point2: points[.leftKnee],
                point3: points[.leftAnkle]
            )

            if let right = rightKneeAngle, let left = leftKneeAngle {
                print(
                    "ğŸ“ ì˜¤ë¥¸ìª½: \(String(format: "%.1f", right))Â°, ì™¼ìª½: \(String(format: "%.1f", left))Â°"
                )
            }
        }

        return BodyAngles(
            rightKnee: rightKneeAngle,
            leftKnee: leftKneeAngle
        )
    }

    /// ì„¸ ì ìœ¼ë¡œ ê°ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    /// - Parameters:
    ///   - point1: ì²« ë²ˆì§¸ ì  (ì˜ˆ: ì–´ê¹¨)
    ///   - point2: ì¤‘ê°„ ì  (ì˜ˆ: íŒ”ê¿ˆì¹˜) - ê°ë„ì˜ ê¼­ì§“ì 
    ///   - point3: ì„¸ ë²ˆì§¸ ì  (ì˜ˆ: ì†ëª©)
    /// - Returns: ê°ë„ (degree)
    private func calculateAngle(
        point1: VNRecognizedPoint?,
        point2: VNRecognizedPoint?,
        point3: VNRecognizedPoint?
    ) -> Double? {
        guard let p1 = point1, let p2 = point2, let p3 = point3 else {
            return nil
        }

        // 1. ë²¡í„° ìƒì„±
        let vector1 = CGPoint(
            x: p1.location.x - p2.location.x,
            y: p1.location.y - p2.location.y
        )
        let vector2 = CGPoint(
            x: p3.location.x - p2.location.x,
            y: p3.location.y - p2.location.y
        )

        // 2. ë‚´ì  ê³„ì‚°
        let dotProduct = vector1.x * vector2.x + vector1.y * vector2.y

        // 3. ë²¡í„° í¬ê¸° ê³„ì‚°
        let magnitude1 = sqrt(vector1.x * vector1.x + vector1.y * vector1.y)
        let magnitude2 = sqrt(vector2.x * vector2.x + vector2.y * vector2.y)

        // 4. ì½”ì‚¬ì¸ ê°’ ê³„ì‚°
        let cosine = dotProduct / (magnitude1 * magnitude2)

        // 5. ë¼ë””ì•ˆì„ ê°ë„ë¡œ ë³€í™˜
        let angleInRadians = acos(min(max(cosine, -1), 1))  // -1 ~ 1 ì‚¬ì´ë¡œ ì œí•œ
        let angleInDegrees = angleInRadians * 180 / .pi

        return angleInDegrees
    }

    /// í˜„ì¬ ì €ì¥ëœ pixelBufferë¥¼ UIImageë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
    private func captureCurrentFrame() -> UIImage? {
        guard let pixelBuffer = currentPixelBuffer else {
            print("âš ï¸ ì €ì¥ëœ pixelBufferê°€ ì—†ìŒ")
            return nil
        }

        guard var image = pixelBufferToUIImage(pixelBuffer) else { return nil }

        if let compressedData = image.jpegData(compressionQuality: 0.8) {
            image = UIImage(data: compressedData) ?? image
            print("ğŸ“¸ ì´ë¯¸ì§€ ìº¡ì²˜ ë° ì••ì¶• ì™„ë£Œ")
        }

        return image
    }

    /// CVPixelBufferë¥¼ UIImageë¡œ ë³€í™˜
    private func pixelBufferToUIImage(_ pixelBuffer: CVPixelBuffer) -> UIImage?
    {
        // 1. CVPixelBufferë¥¼ CIImageë¡œ ë³€í™˜
        let ciImage = CIImage(cvPixelBuffer: pixelBuffer)

        // 2. CIContext ìƒì„± (í•œ ë²ˆë§Œ ìƒì„±í•´ì„œ ì¬ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ)
        let context = CIContext()

        // 3. CIImageë¥¼ CGImageë¡œ ë³€í™˜
        guard let cgImage = context.createCGImage(ciImage, from: ciImage.extent)
        else {
            print("âŒ CGImage ë³€í™˜ ì‹¤íŒ¨")
            return nil
        }

        // 4. CGImageë¥¼ UIImageë¡œ ë³€í™˜
        // ì™¼ìª½ìœ¼ë¡œ 90ë„ íšŒì „ (ì„¸ë¡œ ëª¨ë“œì— ë§ì¶¤)
        let image = UIImage(cgImage: cgImage, scale: 1.0, orientation: .right)

        return image
    }
}

//MARK: ì¤€ë¹„ ìì„¸ ì²´í¬ í•¨ìˆ˜ ì¶”ê°€
extension CameraManager {
    /// í˜„ì¬ ê°ë„ê°€ ì¤€ë¹„ ìì„¸ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
    private func isAngleInReadyRange(_ angle: Double) -> Bool {
        return angle >= readyAngleMin && angle <= readyAngleMax
    }

    /// ì¤€ë¹„ ìì„¸ ì¶”ì  ì‹œì‘
    private func startReadyPositionTracking() {
        readyPositionStartTime = Date()
        isInReadyPosition = true

        // íƒ€ì´ë¨¸ ì‹œì‘ (0.1ì´ˆë§ˆë‹¤ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸)
        readyCheckTimer?.invalidate()
        readyCheckTimer = Timer.scheduledTimer(
            withTimeInterval: 0.1,
            repeats: true
        ) { [weak self] _ in
            self?.updateReadyPositionProgress()
        }
        print("ğŸŸ¡ ì¤€ë¹„ ìì„¸ ê°ì§€ ì‹œì‘")
    }

    /// ì¤€ë¹„ ìì„¸ ì¶”ì  ì¢…ë£Œ
    private func stopReadyPositionTracking() {
        readyPositionStartTime = nil
        isInReadyPosition = false
        readyPositionProgress = 0.0
        readyCheckTimer?.invalidate()
        readyCheckTimer = nil

        print("âšªï¸ ì¤€ë¹„ ìì„¸ í•´ì œ")
    }

    /// ì¤€ë¹„ ìì„¸ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
    private func updateReadyPositionProgress() {
        guard let startTime = readyPositionStartTime else {
            stopReadyPositionTracking()
            return
        }

        let elapsed = Date().timeIntervalSince(startTime)
        let progress = min(elapsed / readyPositionDuration, 1.0)

        DispatchQueue.main.async { [weak self] in
            self?.readyPositionProgress = progress
        }

        // 2ì´ˆ ê²½ê³¼ ì‹œ ìë™ ì¸¡ì • ì‹œì‘
        if elapsed >= readyPositionDuration {
            DispatchQueue.main.async { [weak self] in
                self?.autoStartMeasuring()
            }
        }
    }

    /// ìë™ ì¸¡ì • ì‹œì‘
    private func autoStartMeasuring() {
        guard !isMeasuring else { return }

        print("ğŸ¬ ìë™ ì¸¡ì • ì‹œì‘!")
        stopReadyPositionTracking()
        startMeasuring()
    }

}
